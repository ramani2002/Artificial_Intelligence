{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1c411f",
   "metadata": {},
   "source": [
    "Reference: https://artificialcorner.com/answering-question-about-your-documents-using-langchain-and-not-openai-2f75b8d639ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a730cbd",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install huggingface_hub\n",
    "# !pip install sentence_transformers\n",
    "# !pip install faiss-cpu\n",
    "# !pip install unstructured\n",
    "# !pip install chromadb\n",
    "# !pip install Cython\n",
    "# !pip install tiktoken\n",
    "# !pip install unstructured[local-inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac408719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "# # code you want to evaluate\n",
    "# elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590dcc8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c638d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e248f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader  #for textfiles\n",
    "from langchain.text_splitter import CharacterTextSplitter #text splitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #for using HugginFace models\n",
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS  #facebook vectorizationfrom langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.document_loaders import UnstructuredPDFLoader  #load pdf\n",
    "from langchain.indexes import VectorstoreIndexCreator #vectorize db index with chromadb\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredURLLoader  #load urls into docoument-loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cc4ed",
   "metadata": {},
   "source": [
    "# Get Custom Text File and Load the File\n",
    "\n",
    "This can be scraped, an html, csv, pdf, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71e19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url2 = \"https://github.com/fabiomatricardi/cdQnA/raw/main/KS-all-info_rev1.txt\"\n",
    "res = requests.get(url2)\n",
    "with open(\"KS-all-info_rev1.txt\", \"w\") as f:\n",
    "    f.write(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d355435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('./KS-all-info_rev1.txt')\n",
    "documents = loader.load()\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302e866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"WHAT IS HIERARCHY 4.0\\nwhether you own build manage maintain or operate an oil plant inevitably issues arise that require immediate action and resolution.\\nWith big data flowing in constantly from all sectors making sense of everything while troubleshooting\\nissues without wasting time can be a huge challenge. \\nSo what's the solution?\\nintroducing hierarchy 4.0 and Innovative software solution for control Safety Systems \\nHierarchy 4.0 presents an interactive diagram of the entire plant revealing cause and effect Behavior with readings provided in a hierarchical view allowing for a deep understanding of the system's strategy \\nAll data is collected from multiple sources visualized as a diagram and optimized through a customized dashboard allowing users to run a logic simulation from live data or pick a moment from their history. \\nYour simulation is based on actual safety Logics not just on a math model \\nNow every users can prepare an RCA report 90 percent faster in just a few minutes.\\nHierarchy can be used for any project phase starting from engineering to commissioning and up to operation and maintenance while supporting hazop Hazard analysis by reducing human error and avoiding incorrect documentation.\\nHierarchy 4.0 supports plant operators in decision making taking into account both the safety and the operability of their assets. \\nHierarchy 4.0 Embraces a block log approach: it automatically calculates all Logics affected by an\\noverride and gives a full understanding of constraints. \\nNot convinced let's look at the data! \\nDuring its first project hierarchy 4.0 prevented a revenue loss of 45 million dollars. \\nPlants that utilize hierarchy 4.0 save up to 95 of their time and deliver a return on investment up to five times in value from day one and experience a Personnel utilization and plant efficiency increase by 20 percent per year.\\n\\nTry our demo and make the move to hierarchy 4.0 today\\n\\nCASE STUDIES\\nWe prepared four case studies to show the true potential of Hierarchy 4.0. In each case we are going to review the actual method to approach the issue and the new method, using Hierarchy 4.0, to solve the problem at hand.\\nThe four case studies are 1)Restore a PSD 1 node without requiring a planned shutdown; 2)Evaluate the maintenance on a voting 2 out of 3 instruments; 3)Prepare the maintenance on 2 out of 3 voting where one instrument is already in fault; 4) Prepare a full Root Cause Analysis (RCA) of an unexpected shutdown.\\n\\nCASE STUDY 1 - Restore a PSD 1 node without requiring a planned shutdown, all while the plant remains in normal operation.\\nThis Case Study Challenge is to restore a rack connected to the PSD 1 node without requiring a planned shutdown, all while the plant remains in normal operation. \\nWhat is the actual method: engineer and operator must use the instrument list the get the Rack 2 number of modules (9 AI modules) and verify how many channels they have assigned (8  channels for 9 cards for a total of 72 I/O). This is required to get all the Input/Output connected the Rack 2. All signals that have been identified must be verified in the logical configuration using an engineering workstation: 1)Each signal must be individually inspected in the system applications for its logic function. 2)If a signal is used in multiple controllers, all logics must be cross examined again for all the references. 3)The engineer must prepare a report containing the listed logics and final elements affected during this process.\\nWhat are the actual issues and drawbacks in using the actual method: 1)There is a possibility of human error when checking the connection between signals and logics. \\n2) The Impact Analysis Report has not been correctly updated with the latest software modifications. 3)The troubleshooting process is time consuming due to the involvement of several specialists. 4)Other maintenance activities have been delayed as a result.\\nThe new method is to use Hierarchy 4.0 and you will have your solution in few simple steps.1)Gain access to Hierarchy 4.0 2)Enter Maintenance mode and select the nodes PSD1 and RACK2  3)Obtain the results of your research in a few seconds 4)Get a comprehensive overview of all signals allocated in the specified controller, with emphasis on the signals involved in the rack replacement 5)Easily identify all  the associations between the items and the impacted logics 6)Print from Hierarchy all pages that are affected by the rack replacement 7)Maintain full control of the activity.\\n\\n\", metadata={'source': './KS-all-info_rev1.txt'})]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3f5e8",
   "metadata": {},
   "source": [
    "# Split the Document into Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a98df",
   "metadata": {},
   "source": [
    "LLM cannot accept long instructions. You may be already aware of this, if you have ever worked with ChatGPT or others… there is a token limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8c946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1861, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# Text Splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07170f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033516ea",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0f53e",
   "metadata": {},
   "source": [
    "An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc. The representation captures the semantic meaning of what is being embedded, making it robust for many industry applications.\n",
    "\n",
    "Given the text “What is the meaning of elephant?”, an embedding of the sentence could be represented in a vector space, for example, with a list of 220 numbers (for example, [0.84, 0.42, …, 0.02]). Since this list captures the meaning, we can do exciting things, like calculating the distance between different embeddings to determine how well the meaning of two sentences matches.\n",
    "\n",
    "Embeddings are not limited to text! You can also create an embedding of an image (for example, a list of 220 numbers) and compare it with a text embedding to determine if a sentence describes the image. This concept is under powerful systems for image search, classification, description, and more!\n",
    "\n",
    "How are embeddings generated? The open-source library called Sentence Transformers (https://www.sbert.net/index.html) and this is exactly what we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc7b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b5520f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.embeddings.huggingface.HuggingFaceEmbeddings'>\n",
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "  (2): Normalize()\n",
      ") model_name='sentence-transformers/all-mpnet-base-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5de2f9",
   "metadata": {},
   "source": [
    "# Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6bf4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectorized db\n",
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb040727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.faiss.FAISS object at 0x000001FB27513C10>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d289d32",
   "metadata": {},
   "source": [
    "# Similarity Search: An Specific Application of LLMs!!!\n",
    "\n",
    "Applying Similarity Search to get the best response (document) that matches most closely the user prompt (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad3ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAT IS HIERARCHY 4.0\n",
      "whether you own build manage maintain or operate an oil plant inevitably issues arise that require immediate\n",
      "action and resolution.\n",
      "With big data flowing in constantly from all sectors making sense of everything while troubleshooting\n",
      "issues without wasting time can be a huge challenge.\n",
      "So what's the solution?\n",
      "introducing hierarchy 4.0 and Innovative software solution for control Safety Systems\n",
      "Hierarchy 4.0 presents an interactive diagram of the entire plant revealing cause and effect Behavior with\n",
      "readings provided in a hierarchical view allowing for a deep understanding of the system's strategy\n",
      "All data is collected from multiple sources visualized as a diagram and optimized through a customized\n",
      "dashboard allowing users to run a logic simulation from live data or pick a moment from their history.\n",
      "Your simulation is based on actual safety Logics not just on a math model\n",
      "Now every users can prepare an RCA report 90 percent faster in just a few minutes.\n",
      "Hierarchy can be used for any project phase starting from engineering to commissioning and up to operation and\n",
      "maintenance while supporting hazop Hazard analysis by reducing human error and avoiding incorrect\n",
      "documentation.\n",
      "Hierarchy 4.0 supports plant operators in decision making taking into account both the safety and the\n",
      "operability of their assets.\n",
      "Hierarchy 4.0 Embraces a block log approach: it automatically calculates all Logics affected by an\n",
      "override and gives a full understanding of constraints.\n",
      "Not convinced let's look at the data!\n",
      "During its first project hierarchy 4.0 prevented a revenue loss of 45 million dollars.\n",
      "Plants that utilize hierarchy 4.0 save up to 95 of their time and deliver a return on investment up to five\n",
      "times in value from day one and experience a Personnel utilization and plant efficiency increase by 20 percent\n",
      "per year.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Hierarchy 4.0?\"\n",
    "docs = db.similarity_search(query)\n",
    "len(docs)\n",
    "print(wrap_text_preserve_newlines(str(docs[0].page_content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fdda3",
   "metadata": {},
   "source": [
    "# Talk to our Documens via HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aee8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ae8e3",
   "metadata": {},
   "source": [
    "## Note: google/flant5-xl might take a very long time. So Flan-T5 comes in these sizes:\n",
    "* google/flan-t5-small\n",
    "* google/flan-t5-base\n",
    "* google/flan-t5-large\n",
    "* google/flan-t5-xl\n",
    "* google/flan-t5-xxl\n",
    "\n",
    "Experiment with these and pick the largest model commensurate with compute costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fcef0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe2e04",
   "metadata": {},
   "source": [
    "Reference: Youtube - Prompt Engineering Channel (https://www.youtube.com/@engineerprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9e50fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a possibility of human error when checking the connection between signals and logics.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What the actual issues and drawbacks ?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff663ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your question: What are the actual issues and drawbacks?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There is a possibility of human error when checking the connection between signals and logics. 2) The Impact Analysis Report has not been correctly updated with the latest software modifications.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want an interactive question change the first line in something like this\n",
    "query = input(\"What is your question: \")\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bbeea",
   "metadata": {},
   "source": [
    "# Some Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82974b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm6=HuggingFaceHub(repo_id=\"MBZUAI/LaMini-Flan-T5-783M\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
    "chain = load_qa_chain(llm6, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450d5ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The actual issues and drawbacks of using the actual method are: 1) possibility of human error 2) incorrect impact analysis report 3) time consuming troubleshooting process 4) delayed maintenance activities 5) lack of a comprehensive overview of all signals allocated in the specified controller 6) lack of a user-friendly interface 7) lack of a comprehensive database of all the data 8) lack of a user-friendly interface 9) lack of a user-friendly interface 10) lack of a user-friendly interface'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What the actual issues and drawbacks ?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c79e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The actual method is time consuming due to the involvement of several specialists and other maintenance activities have been delayed as a result. The new method is more efficient and can be used to solve the issue in few simple steps.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2=HuggingFaceHub(repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
    "chain = load_qa_chain(llm2, chain_type=\"stuff\")\n",
    "query = \"What the actual issues and drawbacks ?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd05263",
   "metadata": {},
   "source": [
    "# Experimenting with Other Type of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5845e05",
   "metadata": {},
   "source": [
    "Ful LangChain DocumentLoaders documentation here (https://python.langchain.com/docs/modules/data_connection/document_loaders.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fcaa1",
   "metadata": {},
   "source": [
    "# TO BE CONTINUED..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187829f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97839bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f82caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bd79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ae87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46527211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f1ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.421709999907762\n"
     ]
    }
   ],
   "source": [
    "# code you want to evaluate\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfdc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a4965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11bdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3995f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e58ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
